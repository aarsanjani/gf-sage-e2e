{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch Complete Project Workflow in Amazon SageMaker\n",
    "### Model Deployment\n",
    "    \n",
    "1. [Local Mode endpoint](#LocalModeEndpoint)\n",
    "2. [SageMaker hosted endpoint with model monitoring](#SageMakerHostedEndpoint)\n",
    "3. [Invoking SageMaker endpoints](#InvokingSageMakerEndpoints)\n",
    "4. [Clean up resources](#CleanUp)\n",
    "\n",
    "## Local Mode endpoint <a class=\"anchor\" id=\"LocalModeEndpoint\">\n",
    "\n",
    "While Amazon SageMakerâ€™s Local Mode training is very useful to make sure your training code is working before moving on to full scale training, it also would be useful to have a convenient way to test your model locally before incurring the time and expense of deploying it to production. One possibility is to fetch the XGBoost artifact or a model checkpoint saved in Amazon S3, and load it in your notebook for testing. However, an even easier way to do this is to use the SageMaker Python SDK to do this work for you by setting up a Local Mode endpoint.\n",
    "\n",
    "More specifically, the Estimator object from the Local Mode training job can be used to deploy a model locally. With one exception, this code is the same as the code you would use to deploy to production. In particular, all you need to do is invoke the local Estimator's deploy method, and similarly to Local Mode training, specify the instance type as either `local_gpu` or `local` depending on whether your notebook is on a GPU instance or CPU instance.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll import the variables stored from previous notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parameter_store import ParameterStore\n",
    "import sagemaker\n",
    "from sagemaker.inputs import TrainingInput\n",
    "import numpy as np\n",
    "\n",
    "ps = ParameterStore()\n",
    "parameters = ps.read()\n",
    "\n",
    "bucket = parameters['bucket']\n",
    "s3_prefix = parameters['s3_prefix']\n",
    "raw_s3 = parameters['raw_s3']\n",
    "train_dir = parameters['train_dir']\n",
    "test_dir = parameters['test_dir']\n",
    "train_dir_csv = parameters['train_dir_csv']\n",
    "test_dir_csv = parameters['test_dir_csv']\n",
    "local_model_data = parameters['local_model_data']\n",
    "remote_model_data = parameters['remote_model_data']\n",
    "training_job_name = parameters['training_job_name']\n",
    "tuning_job_name = parameters['tuning_job_name']\n",
    "s3_input_train_uri = parameters['s3_input_train_uri']\n",
    "s3_input_test_uri = parameters['s3_input_test_uri']\n",
    "role = parameters['role']\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "s3_input_train = TrainingInput(s3_input_train_uri, content_type='csv')\n",
    "s3_input_test = TrainingInput(s3_input_test_uri, content_type='csv')\n",
    "inputs = {'train': TrainingInput, 'test': s3_input_test}\n",
    "\n",
    "x_test = np.load('./data/test/x_test.npy')\n",
    "y_test = np.load('./data/test/y_test.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following single line of code deploys the model locally in the SageMaker XGBoost container using the model artifacts from our local training job:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.xgboost.model import XGBoostModel\n",
    "\n",
    "local_model = XGBoostModel(entry_point='train_deploy.py', model_data=local_model_data, role=role, framework_version='1.0-1')\n",
    "local_predictor = local_model.deploy(initial_instance_count=1, instance_type='local')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get predictions from the Local Mode endpoint, simply invoke the Predictor's predict method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "local_predictor.serializer = CSVSerializer()\n",
    "local_predictor.deserializer = JSONDeserializer()\n",
    "\n",
    "local_predictor.predict(x_test[0], initial_args={'Accept': 'text/csv'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check, the predictions can be compared against the actual target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_results = [local_predictor.predict(x_test[i], initial_args={'Accept': 'text/csv'}) for i in range(0, 10)]\n",
    "print(f'predictions: \\t {local_results}')\n",
    "print(f'target values: \\t {y_test[:10]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only trained the model for a few rounds, but the predictions so far should at least appear reasonably within the ballpark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid having the SageMaker TensorFlow Serving container indefinitely running locally, simply gracefully shut it down by calling the `delete_endpoint` method of the Predictor object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker hosted endpoint with model monitoring <a class=\"anchor\" id=\"SageMakerHostedEndpoint\">\n",
    "\n",
    "Assuming the best model from the tuning job is better than the model produced by the individual Hosted Training job above, we could now easily deploy that model to production.  A convenient option is to use a SageMaker hosted endpoint, which serves real time predictions from the trained model (Batch Transform jobs also are available for asynchronous, offline predictions on large datasets). The endpoint will retrieve the XGBoost saved model created during training and deploy it within a SageMaker XGBoost Serving container. This all can be accomplished with one line of code.  \n",
    "\n",
    "More specifically, by calling the `deploy` method of the HyperparameterTuner object we instantiated above, we can directly deploy the best model from the tuning job to a SageMaker hosted endpoint.  It will take several minutes longer to deploy the model to the hosted endpoint compared to the Local Mode endpoint, which is more useful for fast prototyping of inference code.\n",
    "    \n",
    "In this example, we'll also be including Model Monitor to monitor the requests to the hosted endpoint for data drift."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First setup Model Monitor's Data Capture for the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import DataCaptureConfig\n",
    "\n",
    "s3_capture_upload_path = f's3://{bucket}/{s3_prefix}/model_monitor'\n",
    "\n",
    "data_capture_config = DataCaptureConfig(\n",
    "                        enable_capture=True,\n",
    "                        sampling_percentage=100,\n",
    "                        destination_s3_uri=s3_capture_upload_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now deploy the hosted endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.xgboost import XGBoostModel\n",
    "\n",
    "model = XGBoostModel(entry_point='train_deploy.py', model_data=remote_model_data,\n",
    "                     role=role, framework_version='1.0-1',\n",
    "                     name='xgboost-model-from-hosted-endpoint')\n",
    "\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type='ml.t2.medium',\n",
    "                         endpoint_name='xgboost-housing', data_capture_config=data_capture_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get predictions from the hosted endpoint, simply invoke the Predictor's predict method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.serializer = CSVSerializer()\n",
    "predictor.deserializer = JSONDeserializer()\n",
    "\n",
    "predictor.predict(x_test[0], initial_args={'Accept': 'text/csv'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare the predictions generated by this endpoint with those generated locally by the Local Mode endpoint: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hosted_results = [predictor.predict(x_test[i], initial_args={'Accept': 'text/csv'}) for i in range(0, 10)]\n",
    "print(f'local predictions: \\t {local_results}')\n",
    "print(f'hosted predictions: \\t {hosted_results}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Monitor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon SageMaker Model Monitor continuously monitors the quality of Amazon SageMaker machine learning models in production. With Model Monitor, you can set alerts that notify you when there are deviations in the model quality. Early and proactive detection of these deviations enables you to take corrective actions, such as retraining models, auditing upstream systems, or fixing quality issues without having to monitor models manually or build additional tooling. You can use Model Monitor prebuilt monitoring capabilities that do not require coding. You also have the flexibility to monitor models by coding to provide custom analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to create a baseline so Model Monitor can generate baseline statistics for the training data.\n",
    "\n",
    "These [statistics](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-interpreting-statistics.html) include mean, standard deviation, min, max, distribution, and percentage of missing data. We can see some of those statistics in our training data below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "x_train = np.load('./data/train/x_train.npy')\n",
    "x_train_df = pd.DataFrame(x_train)\n",
    "x_train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's the distribution of our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of all features\n",
    "x_train_df.plot.kde(subplots=True, layout=(4,4), figsize=(20, 9));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's generate the full set of statistics and constraints now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import DefaultModelMonitor\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "import numpy as np\n",
    "\n",
    "# Baseline data of the training data that we saved as CSV\n",
    "baseline_data_uri = f's3://{bucket}/{s3_prefix}/data/train/train.csv'\n",
    "baseline_results_uri = f's3://{bucket}/{s3_prefix}/model_monitor/baseline_output'\n",
    "\n",
    "my_default_monitor = DefaultModelMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=3600,\n",
    ")\n",
    "\n",
    "my_default_monitor.suggest_baseline(\n",
    "    baseline_dataset=baseline_data_uri,\n",
    "    dataset_format=DatasetFormat.csv(header=False),\n",
    "    output_s3_uri=baseline_results_uri,\n",
    "    wait=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The constraints are auto-generated based off the training data statistics that are calculated. The constraints represent thresholds around distribution parameters, missing value percentages, and other statistics. More information on constraints can be found [here](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-byoc-constraints.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With constraints and statistics in hand, we can create a monitoring schedule so that Model Monitor will monitor the statistics of the incoming request data and compare it to the baseline training statistics and constraints in order to detect violations. Violations include:\n",
    "\n",
    "- `data_type_check`\n",
    "- `completeness_check`\n",
    "- `baseline_drift_check` (distance is calculated by getting the maximum absolute difference between the cumulative distribution functions of two distributions and compared to a threshold)\n",
    "- `missing_column_check`\n",
    "- `extra_column_check`\n",
    "- `categorical_values_check`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversample training data to skew distributions of features\n",
    "# Sampling with respect to the distribution of one of our features\n",
    "oversampled_requests_df = x_train_df.sample(frac=.4, replace=True, random_state=123, weights=x_train_df.groupby(6)[6].transform('count'))\n",
    "print(oversampled_requests_df.describe())\n",
    "\n",
    "# Plot distribution of features\n",
    "x_train_df.plot.kde(subplots=True, layout=(4,4), figsize=(20, 9), title='(BEFORE) Distribution of training features');\n",
    "oversampled_requests_df.plot.kde(subplots=True, layout=(4,4), figsize=(20, 9), title='(AFTER) Distribution of features across request data');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there is a considerable difference between some of the training feature distributions and some of the request distributions, Model Monitor would likely trigger a violation and output a `constraint_violations.csv` file in the following location: `s3://{bucket}/{s3_prefix}/model_monitor/violations`. The contents of the file might look something like this:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"violations\" : [ {\n",
    "    \"feature_name\" : \"_c1\",\n",
    "    \"constraint_check_type\" : \"baseline_drift_check\",\n",
    "    \"description\" : \"Baseline drift distance: 0.18977610005771073 exceeds threshold: 0.1\"\n",
    "  }, {\n",
    "    \"feature_name\" : \"_c8\",\n",
    "    \"constraint_check_type\" : \"baseline_drift_check\",\n",
    "    \"description\" : \"Baseline drift distance: 0.32592205342200775 exceeds threshold: 0.1\"\n",
    "  } ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's create the monitoring job that will monitor the statistics of the incoming request data and compare it to the baseline training statistics to detect violations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import CronExpressionGenerator\n",
    "\n",
    "baseline_violations_uri = f's3://{bucket}/{s3_prefix}/model_monitor/violations'\n",
    "\n",
    "monitor_schedule_name = 'xgboost-boston-housing-model-monitor-schedule'\n",
    "\n",
    "my_default_monitor.create_monitoring_schedule(\n",
    "    monitor_schedule_name=monitor_schedule_name,\n",
    "    endpoint_input='xgboost-housing',\n",
    "    output_s3_uri=baseline_violations_uri,\n",
    "    statistics=my_default_monitor.baseline_statistics(),\n",
    "    constraints=my_default_monitor.suggested_constraints(),\n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly(),\n",
    "    enable_cloudwatch_metrics=True,\n",
    ")\n",
    "\n",
    "desc_schedule_result = my_default_monitor.describe_schedule()\n",
    "print('Schedule status: {}'.format(desc_schedule_result['MonitoringScheduleStatus']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, while you're testing, you could simulate a violation happening by just uploading an empty `constraint_violations.csv` file which could trigger a Lambda function to kick off a re-training pipeline for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to simulate a violation happening\n",
    "# !touch constraint_violations.csv\n",
    "# out = f's3://{bucket}/{s3_prefix}/model_monitor/violations/constraint_violations.csv'\n",
    "# !aws s3 cp ./constraint_violations.csv {out}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker hosted endpoint with autotuned parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import HyperparameterTuner, IntegerParameter\n",
    "\n",
    "# Parameters from last notebook\n",
    "hyperparameter_ranges = {\n",
    "  'num_round': IntegerParameter(2, 10)\n",
    "}\n",
    "\n",
    "tuner_parameters = {'estimator':model,\n",
    "                    'objective_metric_name':'validation:aucpr',\n",
    "                    'hyperparameter_ranges':hyperparameter_ranges,\n",
    "                    #'metric_definitions':metric_definitions,\n",
    "                    'max_jobs':4,\n",
    "                    'max_parallel_jobs':2}\n",
    "tuner_parameters['estimator'] = model\n",
    "\n",
    "tuner = HyperparameterTuner(**tuner_parameters)\n",
    "tuner = tuner.attach(tuning_job_name)\n",
    "tuning_predictor = tuner.deploy(initial_instance_count=1, instance_type='ml.t2.medium',\n",
    "                                endpoint_name='xgboost-housing-auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare the predictions generated by this endpoint with those generated locally by the Local Mode endpoint: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_predictor.content_type = 'text/csv'\n",
    "tuning_predictor.accept = 'text/csv'\n",
    "tuning_predictor.serializer = csv_serializer\n",
    "tuning_predictor.deserializer = json_deserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hosted_results = [tuning_predictor.predict(x_test[i]) for i in range(0, 10)]\n",
    "print(f'local predictions: \\t {local_results}')\n",
    "print(f'tuner predictions: \\t {hosted_results}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoking SageMaker Endpoints <a class=\"anchor\" id=\"InvokingSageMakerEndpoints\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's restore the endpoint names we created from our parameters file just in case you decided to shut down the kernel or notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code so far, we've seen examples of training a model, deploying it as an endpoint, then using that deployed model object to do predictions. But what if we want to call an existing SageMaker endpoint? Well, there are a couple ways to do this. The first is with SageMaker's Python SDK and the second with boto3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling an endpoint with SageMaker's Python SDK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.predictor import RealTimePredictor\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "predictor = RealTimePredictor(endpoint='xgboost-housing',\n",
    "                              sagemaker_session=sess,\n",
    "                              serializer=csv_serializer,\n",
    "                              deserializer=json_deserializer)\n",
    "\n",
    "predictor.predict(x_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or call an endpoint using boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "sm_runtime = boto3.client('sagemaker-runtime')\n",
    "# Create a CSV string from the numpy array\n",
    "payload = ', '.join([str(each) for each in x_test[0]])\n",
    "prediction = sm_runtime.invoke_endpoint(EndpointName='xgboost-housing',\n",
    "                                        ContentType='text/csv',\n",
    "                                        Body=payload)\n",
    "prediction = json.loads(prediction['Body'].read())\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up <a class=\"anchor\" id=\"CleanUp\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid billing charges from stray resources, you can delete the prediction endpoint to release its associated instance(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint(delete_endpoint_config=True)\n",
    "tuning_predictor.delete_endpoint(delete_endpoint_config=True)\n",
    "!aws sagemaker delete-monitoring-schedule --monitoring-schedule-name xgboost-boston-housing-model-monitor-schedule"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
